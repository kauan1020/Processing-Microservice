"""Add new tables and update existing ones

Revision ID: 932656f99eee
Revises: 2728e6383a58
Create Date: 2025-06-17 21:08:09.889476

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '932656f99eee'
down_revision: Union[str, None] = '2728e6383a58'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###

    # Create new tables first
    op.create_table('audit_logs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.String(length=255), nullable=True),
    sa.Column('action', sa.String(length=100), nullable=False),
    sa.Column('resource_type', sa.String(length=50), nullable=False),
    sa.Column('resource_id', sa.String(length=255), nullable=True),
    sa.Column('details', sa.JSON(), nullable=True),
    sa.Column('ip_address', sa.String(length=45), nullable=True),
    sa.Column('user_agent', sa.String(length=500), nullable=True),
    sa.Column('success', sa.Boolean(), nullable=False),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('timestamp', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_audit_logs_action'), 'audit_logs', ['action'], unique=False)
    op.create_index(op.f('ix_audit_logs_id'), 'audit_logs', ['id'], unique=False)
    op.create_index(op.f('ix_audit_logs_resource_id'), 'audit_logs', ['resource_id'], unique=False)
    op.create_index(op.f('ix_audit_logs_resource_type'), 'audit_logs', ['resource_type'], unique=False)
    op.create_index(op.f('ix_audit_logs_success'), 'audit_logs', ['success'], unique=False)
    op.create_index(op.f('ix_audit_logs_timestamp'), 'audit_logs', ['timestamp'], unique=False)
    op.create_index(op.f('ix_audit_logs_user_id'), 'audit_logs', ['user_id'], unique=False)

    op.create_table('file_storage',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=True),
    sa.Column('user_id', sa.String(length=255), nullable=False),
    sa.Column('file_type', sa.String(length=20), nullable=False),
    sa.Column('file_path', sa.String(length=1000), nullable=False),
    sa.Column('original_filename', sa.String(length=500), nullable=True),
    sa.Column('file_size', sa.Integer(), nullable=False),
    sa.Column('mime_type', sa.String(length=100), nullable=True),
    sa.Column('checksum', sa.String(length=64), nullable=True),
    sa.Column('storage_backend', sa.String(length=50), nullable=False),
    sa.Column('is_temporary', sa.Boolean(), nullable=False),
    sa.Column('expires_at', sa.DateTime(), nullable=True),
    sa.Column('accessed_at', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('file_path')
    )
    op.create_index(op.f('ix_file_storage_created_at'), 'file_storage', ['created_at'], unique=False)
    op.create_index(op.f('ix_file_storage_expires_at'), 'file_storage', ['expires_at'], unique=False)
    op.create_index(op.f('ix_file_storage_file_type'), 'file_storage', ['file_type'], unique=False)
    op.create_index(op.f('ix_file_storage_id'), 'file_storage', ['id'], unique=False)
    op.create_index(op.f('ix_file_storage_is_temporary'), 'file_storage', ['is_temporary'], unique=False)
    op.create_index(op.f('ix_file_storage_job_id'), 'file_storage', ['job_id'], unique=False)
    op.create_index(op.f('ix_file_storage_user_id'), 'file_storage', ['user_id'], unique=False)

    op.create_table('notification_logs',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=True),
    sa.Column('user_id', sa.String(length=255), nullable=False),
    sa.Column('notification_type', sa.String(length=50), nullable=False),
    sa.Column('recipient_email', sa.String(length=320), nullable=False),
    sa.Column('subject', sa.String(length=500), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('delivery_attempts', sa.Integer(), nullable=False),
    sa.Column('last_attempt_at', sa.DateTime(), nullable=True),
    sa.Column('delivered_at', sa.DateTime(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('notification_data', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_notification_logs_created_at'), 'notification_logs', ['created_at'], unique=False)
    op.create_index(op.f('ix_notification_logs_id'), 'notification_logs', ['id'], unique=False)
    op.create_index(op.f('ix_notification_logs_job_id'), 'notification_logs', ['job_id'], unique=False)
    op.create_index(op.f('ix_notification_logs_notification_type'), 'notification_logs', ['notification_type'], unique=False)
    op.create_index(op.f('ix_notification_logs_recipient_email'), 'notification_logs', ['recipient_email'], unique=False)
    op.create_index(op.f('ix_notification_logs_status'), 'notification_logs', ['status'], unique=False)
    op.create_index(op.f('ix_notification_logs_user_id'), 'notification_logs', ['user_id'], unique=False)

    op.create_table('processing_queue',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('job_id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.String(length=255), nullable=False),
    sa.Column('priority', sa.Integer(), nullable=False),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('worker_id', sa.String(length=255), nullable=True),
    sa.Column('retry_count', sa.Integer(), nullable=False),
    sa.Column('max_retries', sa.Integer(), nullable=False),
    sa.Column('scheduled_at', sa.DateTime(), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('processing_data', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_processing_queue_created_at'), 'processing_queue', ['created_at'], unique=False)
    op.create_index(op.f('ix_processing_queue_id'), 'processing_queue', ['id'], unique=False)
    op.create_index(op.f('ix_processing_queue_job_id'), 'processing_queue', ['job_id'], unique=False)
    op.create_index(op.f('ix_processing_queue_priority'), 'processing_queue', ['priority'], unique=False)
    op.create_index(op.f('ix_processing_queue_scheduled_at'), 'processing_queue', ['scheduled_at'], unique=False)
    op.create_index(op.f('ix_processing_queue_status'), 'processing_queue', ['status'], unique=False)
    op.create_index(op.f('ix_processing_queue_user_id'), 'processing_queue', ['user_id'], unique=False)
    op.create_index(op.f('ix_processing_queue_worker_id'), 'processing_queue', ['worker_id'], unique=False)

    op.create_table('system_metrics',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('metric_type', sa.String(length=50), nullable=False),
    sa.Column('metric_name', sa.String(length=100), nullable=False),
    sa.Column('metric_value', sa.Float(), nullable=False),
    sa.Column('unit', sa.String(length=20), nullable=True),
    sa.Column('tags', sa.JSON(), nullable=True),
    sa.Column('timestamp', sa.DateTime(), nullable=False),
    sa.Column('worker_id', sa.String(length=255), nullable=True),
    sa.Column('job_id', sa.UUID(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_system_metrics_id'), 'system_metrics', ['id'], unique=False)
    op.create_index(op.f('ix_system_metrics_job_id'), 'system_metrics', ['job_id'], unique=False)
    op.create_index(op.f('ix_system_metrics_metric_name'), 'system_metrics', ['metric_name'], unique=False)
    op.create_index(op.f('ix_system_metrics_metric_type'), 'system_metrics', ['metric_type'], unique=False)
    op.create_index(op.f('ix_system_metrics_timestamp'), 'system_metrics', ['timestamp'], unique=False)
    op.create_index(op.f('ix_system_metrics_worker_id'), 'system_metrics', ['worker_id'], unique=False)

    op.create_table('workers',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('worker_id', sa.String(length=255), nullable=False),
    sa.Column('hostname', sa.String(length=255), nullable=False),
    sa.Column('ip_address', sa.String(length=45), nullable=True),
    sa.Column('port', sa.Integer(), nullable=True),
    sa.Column('status', sa.String(length=20), nullable=False),
    sa.Column('max_concurrent_jobs', sa.Integer(), nullable=False),
    sa.Column('current_job_count', sa.Integer(), nullable=False),
    sa.Column('total_jobs_processed', sa.Integer(), nullable=False),
    sa.Column('total_processing_time', sa.Float(), nullable=False),
    sa.Column('last_heartbeat', sa.DateTime(), nullable=False),
    sa.Column('capabilities', sa.JSON(), nullable=True),
    sa.Column('resource_usage', sa.JSON(), nullable=True),
    sa.Column('version', sa.String(length=50), nullable=True),
    sa.Column('started_at', sa.DateTime(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_workers_id'), 'workers', ['id'], unique=False)
    op.create_index(op.f('ix_workers_last_heartbeat'), 'workers', ['last_heartbeat'], unique=False)
    op.create_index(op.f('ix_workers_status'), 'workers', ['status'], unique=False)
    op.create_index(op.f('ix_workers_worker_id'), 'workers', ['worker_id'], unique=True)

    # Now update existing video_jobs table

    # Add new columns first
    op.add_column('video_jobs', sa.Column('video_format', sa.String(length=10), nullable=True))
    op.add_column('video_jobs', sa.Column('duration', sa.Float(), nullable=True))
    op.add_column('video_jobs', sa.Column('frame_rate', sa.Float(), nullable=True))
    op.add_column('video_jobs', sa.Column('zip_file_path', sa.String(length=1000), nullable=True))
    op.add_column('video_jobs', sa.Column('zip_file_size', sa.Integer(), nullable=True))
    op.add_column('video_jobs', sa.Column('processing_started_at', sa.DateTime(), nullable=True))
    op.add_column('video_jobs', sa.Column('processing_completed_at', sa.DateTime(), nullable=True))
    op.add_column('video_jobs', sa.Column('job_metadata', sa.JSON(), nullable=True))

    # Update video_format with default value for existing records
    op.execute("UPDATE video_jobs SET video_format = 'mp4' WHERE video_format IS NULL")

    # Make video_format NOT NULL after setting default values
    op.alter_column('video_jobs', 'video_format', nullable=False)

    # Handle ID conversion from VARCHAR to UUID
    # First, create a temporary column
    op.add_column('video_jobs', sa.Column('id_new', sa.UUID(), nullable=True))

    # Generate UUIDs for existing records that don't have valid UUID format
    op.execute("""
        UPDATE video_jobs 
        SET id_new = gen_random_uuid()
        WHERE id_new IS NULL
    """)

    # Make the new column NOT NULL
    op.alter_column('video_jobs', 'id_new', nullable=False)

    # Drop the old primary key constraint
    op.drop_constraint('video_jobs_pkey', 'video_jobs', type_='primary')

    # Drop the old id column
    op.drop_column('video_jobs', 'id')

    # Rename the new column to id
    op.alter_column('video_jobs', 'id_new', new_column_name='id')

    # Create new primary key constraint
    op.create_primary_key('video_jobs_pkey', 'video_jobs', ['id'])

    # Update other columns
    op.alter_column('video_jobs', 'user_id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.String(length=255),
               existing_nullable=False)
    op.alter_column('video_jobs', 'original_filename',
               existing_type=sa.VARCHAR(length=255),
               type_=sa.String(length=500),
               existing_nullable=False)
    op.alter_column('video_jobs', 'file_path',
               existing_type=sa.VARCHAR(length=500),
               type_=sa.String(length=1000),
               nullable=False)
    op.alter_column('video_jobs', 'file_size',
               existing_type=sa.INTEGER(),
               nullable=False)
    op.alter_column('video_jobs', 'extraction_fps',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=False)

    # Create indexes
    op.create_index(op.f('ix_video_jobs_created_at'), 'video_jobs', ['created_at'], unique=False)
    op.create_index(op.f('ix_video_jobs_id'), 'video_jobs', ['id'], unique=False)
    op.create_index(op.f('ix_video_jobs_status'), 'video_jobs', ['status'], unique=False)
    op.create_index(op.f('ix_video_jobs_user_id'), 'video_jobs', ['user_id'], unique=False)

    # Drop old columns
    columns_to_drop = [
        'job_config', 'error_details', 'frames_path', 'filename', 'output_format',
        'max_frames', 'quality', 'completed_at', 'progress', 'files_cleaned',
        'started_at', 'output_path', 'is_deleted', 'result_data',
        'processing_duration', 'end_time', 'start_time'
    ]

    for column in columns_to_drop:
        try:
            op.drop_column('video_jobs', column)
        except Exception:
            # Column might not exist, continue
            pass

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Note: This downgrade is complex and may result in data loss
    # Consider backing up data before running this

    # Add back old columns
    op.add_column('video_jobs', sa.Column('start_time', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('end_time', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('processing_duration', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('result_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('is_deleted', sa.BOOLEAN(), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('output_path', sa.VARCHAR(length=500), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('files_cleaned', sa.BOOLEAN(), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('progress', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('quality', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('max_frames', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('output_format', sa.VARCHAR(length=10), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('filename', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
    op.add_column('video_jobs', sa.Column('frames_path', sa.VARCHAR(length=500), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('error_details', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))
    op.add_column('video_jobs', sa.Column('job_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True))

    # Drop indexes
    op.drop_index(op.f('ix_video_jobs_user_id'), table_name='video_jobs')
    op.drop_index(op.f('ix_video_jobs_status'), table_name='video_jobs')
    op.drop_index(op.f('ix_video_jobs_id'), table_name='video_jobs')
    op.drop_index(op.f('ix_video_jobs_created_at'), table_name='video_jobs')

    # Revert column changes
    op.alter_column('video_jobs', 'extraction_fps',
               existing_type=sa.DOUBLE_PRECISION(precision=53),
               nullable=True)
    op.alter_column('video_jobs', 'file_size',
               existing_type=sa.INTEGER(),
               nullable=True)
    op.alter_column('video_jobs', 'file_path',
               existing_type=sa.String(length=1000),
               type_=sa.VARCHAR(length=500),
               nullable=True)
    op.alter_column('video_jobs', 'original_filename',
               existing_type=sa.String(length=500),
               type_=sa.VARCHAR(length=255),
               existing_nullable=False)
    op.alter_column('video_jobs', 'user_id',
               existing_type=sa.String(length=255),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)

    # Convert ID back to VARCHAR (this will cause data loss for UUIDs)
    op.drop_constraint('video_jobs_pkey', 'video_jobs', type_='primary')
    op.alter_column('video_jobs', 'id',
               existing_type=sa.UUID(),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)
    op.create_primary_key('video_jobs_pkey', 'video_jobs', ['id'])

    # Drop new columns
    op.drop_column('video_jobs', 'job_metadata')
    op.drop_column('video_jobs', 'processing_completed_at')
    op.drop_column('video_jobs', 'processing_started_at')
    op.drop_column('video_jobs', 'zip_file_size')
    op.drop_column('video_jobs', 'zip_file_path')
    op.drop_column('video_jobs', 'frame_rate')
    op.drop_column('video_jobs', 'duration')
    op.drop_column('video_jobs', 'video_format')

    # Drop new tables
    op.drop_table('workers')
    op.drop_table('system_metrics')
    op.drop_table('processing_queue')
    op.drop_table('notification_logs')
    op.drop_table('file_storage')
    op.drop_table('audit_logs')
    # ### end Alembic commands ###